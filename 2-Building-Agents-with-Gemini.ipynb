{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: SETUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI library\n",
    "#!pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "# Import the new function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "# This cell handles API key configuration for Google Gemini.\n",
    "\n",
    "try:\n",
    "    # Load the API key using the custom function from helper.py\n",
    "    api_key = get_gemini_api_key()\n",
    "\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Core Agent Logic and Tool Structure\n",
    "\n",
    "Here are the reusable components: \n",
    "- the `GeminiAgent` class that manages state, the simple tool definitions that the model sees, their corresponding Python implementations, and \n",
    "- the main `run_agent_turn` function that handles the interaction loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Class ---\n",
    "from google.generativeai.types import content_types\n",
    "import time\n",
    "\n",
    "class GeminiAgent:\n",
    "    \"\"\"A class to simulate an agent's state and memory.\"\"\"\n",
    "    def __init__(self, model_name, system_prompt=\"\", memory_blocks=None, tools=None):\n",
    "        self.id = f\"agent-{uuid.uuid4()}\"\n",
    "        self.memory_blocks = memory_blocks if memory_blocks else {}\n",
    "        self.tools = tools if tools else []\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            tools=self.tools\n",
    "        )\n",
    "        self.chat_session = self.model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "    def get_formatted_memory(self):\n",
    "        \"\"\"Formats memory blocks into a string for the system prompt.\"\"\"\n",
    "        if not self.memory_blocks:\n",
    "            return \"No memory blocks are configured.\"\n",
    "\n",
    "        formatted_string = \"--- CORE MEMORY ---\\n\"\n",
    "        for label, value in self.memory_blocks.items():\n",
    "            if isinstance(value, list):\n",
    "                val_str = json.dumps(value)\n",
    "            else:\n",
    "                val_str = str(value)\n",
    "            formatted_string += f\"<{label}>\\n{val_str}\\n</{label}>\\n\"\n",
    "        return formatted_string.strip()\n",
    "\n",
    "# --- Tool Definitions (for the model) ---\n",
    "def get_agent_id():\n",
    "    \"\"\"Query your agent ID field.\"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_push(task_description: str):\n",
    "    \"\"\"\n",
    "    Push a task to a task queue stored in the agent's core memory.\n",
    "    Args:\n",
    "        task_description (str): A description of the task to be added.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_pop():\n",
    "    \"\"\"Get and remove the next task from the task queue.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# --- Tool Implementations (for Python) ---\n",
    "def _get_agent_id_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for getting the agent ID.\"\"\"\n",
    "    return agent.id\n",
    "\n",
    "def _task_queue_push_impl(agent: GeminiAgent, task_description: str):\n",
    "    \"\"\"Implementation for pushing a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not isinstance(agent.memory_blocks[\"tasks\"], list):\n",
    "        agent.memory_blocks[\"tasks\"] = []\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    tasks.append(task_description)\n",
    "    return f\"Task '{task_description}' was added. Current tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "def _task_queue_pop_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for popping a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not isinstance(agent.memory_blocks[\"tasks\"], list):\n",
    "        return \"The task queue is empty.\"\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    popped_task = tasks.pop(0)\n",
    "    return f\"Completed task: '{popped_task}'. Remaining tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "\n",
    "# --- Generic Agent Interaction Loop ---\n",
    "def run_agent_turn(agent, tool_registry, user_message):\n",
    "    \"\"\"Handles a single turn of conversation with an agent, including tool calls.\"\"\"\n",
    "    print_markdown(f\"### ðŸ‘¤ User: {user_message}\")\n",
    "    print(\"---\")\n",
    "\n",
    "    full_prompt = f\"{agent.system_prompt}\\n\\n{agent.get_formatted_memory()}\\n\\nUser Message: {user_message}\"\n",
    "    \n",
    "    history = [\n",
    "        {'role': 'user', 'parts': [{'text': full_prompt}]}\n",
    "    ]\n",
    "\n",
    "    response = agent.model.generate_content(history, tools=agent.tools)\n",
    "    time.sleep(1) # Add a delay to avoid rate limiting\n",
    "    message = response.candidates[0].content\n",
    "    history.append(message)\n",
    "\n",
    "    # Keep track of whether the last action was a tool call\n",
    "    last_action_was_tool = False\n",
    "\n",
    "    while any(part.function_call for part in message.parts):\n",
    "        last_action_was_tool = True\n",
    "        # Create a list to hold the responses for each function call\n",
    "        tool_response_parts = []\n",
    "\n",
    "        for part in message.parts:\n",
    "            if not part.function_call:\n",
    "                continue\n",
    "\n",
    "            fc = part.function_call\n",
    "            tool_name = fc.name\n",
    "            tool_args = dict(fc.args)\n",
    "\n",
    "            print(f\"ðŸ§  **Reasoning:** Model wants to call `{tool_name}`.\")\n",
    "            print(f\"ðŸ”§ **Tool Call:** `{tool_name}` with arguments: `{tool_args}`\\n\" + \"---\")\n",
    "\n",
    "            if tool_name in tool_registry:\n",
    "                result = tool_registry[tool_name](**tool_args)\n",
    "            else:\n",
    "                result = f\"Error: Tool '{tool_name}' not found.\"\n",
    "\n",
    "            print(f\"ðŸ”§ **Tool Return:**\\n```\\n{result}\\n```\\n\" + \"---\")\n",
    "            \n",
    "            # Append the response for this specific tool call\n",
    "            tool_response_parts.append({\n",
    "                \"function_response\": {\n",
    "                    \"name\": tool_name,\n",
    "                    \"response\": {\"content\": result}\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Send all tool responses back to the model in a single turn\n",
    "        tool_response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"parts\": tool_response_parts\n",
    "        }\n",
    "        history.append(tool_response)\n",
    "        \n",
    "        response = agent.model.generate_content(history, tools=agent.tools)\n",
    "        time.sleep(1) # Add a delay to avoid rate limiting\n",
    "        message = response.candidates[0].content\n",
    "        history.append(message)\n",
    "\n",
    "    # After the tool-calling loop, if the last action was a tool call,\n",
    "    # we need to explicitly ask the model for a final summary.\n",
    "    if last_action_was_tool:\n",
    "        print(\"ðŸ§  **Reasoning:** All tools have been executed. Generating final summary response.\")\n",
    "        \n",
    "        # Add a new prompt to guide the model's final response\n",
    "        history.append({\n",
    "            'role': 'user',\n",
    "            'parts': [{'text': \"Excellent, all tasks are complete. Please provide a final, summary response to the user now, including any creative content you were asked to generate.\"}]\n",
    "        })\n",
    "\n",
    "        # Make one final call (without tools) to get the concluding text\n",
    "        final_response = agent.model.generate_content(history)\n",
    "        final_text = final_response.candidates[0].content.parts[0].text\n",
    "    else:\n",
    "        # If the last message already had text and wasn't a tool call, use that.\n",
    "        final_text = message.parts[0].text if message.parts and message.parts[0].text else \"I have completed the task.\"\n",
    "\n",
    "    print_markdown(f\"### ðŸ¤– Agent: {final_text}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Section 1: Memory Management Simulation\n",
    "\n",
    "This block uses the core logic to create the first agent and demonstrates how to initialize and view its `memory blocks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Section 1: Memory Management Simulation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with ID: agent-a16041f6-98b3-4b73-ac3b-9f90ece6914e\n",
      "\n",
      "All memory blocks:\n",
      "{\n",
      "  \"human\": \"The human's name is Bob the Builder.\",\n",
      "  \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
      "}\n",
      "\n",
      "Formatted memory prompt:\n",
      "--- CORE MEMORY ---\n",
      "<human>\n",
      "The human's name is Bob the Builder.\n",
      "</human>\n",
      "<persona>\n",
      "My name is Sam, the all-knowing sentient AI.\n",
      "</persona>\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Section 1: Memory Management Simulation ---\n",
    "print_markdown(\"## Section 1: Memory Management Simulation\")\n",
    "\n",
    "agent1 = GeminiAgent(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    memory_blocks={\n",
    "        \"human\": \"The human's name is Bob the Builder.\",\n",
    "        \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
    "    }\n",
    ")\n",
    "print(f\"Agent created with ID: {agent1.id}\\n\")\n",
    "print(\"All memory blocks:\")\n",
    "print(json.dumps(agent1.memory_blocks, indent=2))\n",
    "print(\"\\nFormatted memory prompt:\")\n",
    "print(agent1.get_formatted_memory())\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Section 2: Accessing Agent State with Tools\n",
    "Here, we create a second agent and give it the get_agent_id tool to allow it to access its own state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Section 2: Accessing Agent State with Tools"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ‘¤ User: What is your agent id?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "ðŸ§  **Reasoning:** Model wants to call `get_agent_id`.\n",
      "ðŸ”§ **Tool Call:** `get_agent_id` with arguments: `{}`\n",
      "---\n",
      "ðŸ”§ **Tool Return:**\n",
      "```\n",
      "agent-74eabf1a-b0bc-48b7-a8da-f4871e02f5ae\n",
      "```\n",
      "---\n",
      "ðŸ§  **Reasoning:** All tools have been executed. Generating final summary response.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ¤– Agent: All tasks are complete.  I have no creative content to share as no such tasks were requested.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Section 2: Accessing Agent State with Tools ---\n",
    "print_markdown(\"## Section 2: Accessing Agent State with Tools\")\n",
    "\n",
    "# The agent is initialized with the tool *definition*\n",
    "agent2 = GeminiAgent(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    tools=[get_agent_id]\n",
    ")\n",
    "\n",
    "# The tool registry maps the tool name to its *implementation*\n",
    "tool_registry_2 = {\n",
    "    \"get_agent_id\": lambda: _get_agent_id_impl(agent2)\n",
    "}\n",
    "\n",
    "run_agent_turn(agent2, tool_registry_2, \"What is your agent id?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Section 3: Custom Task Queue Memory\n",
    "Finally, this section creates the more advanced task_agent that uses tools to modify its own memory, creating a simple task queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Section 3: Custom Task Queue Memory"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial task list: []\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ‘¤ User: Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "ðŸ§  **Reasoning:** Model wants to call `task_queue_push`.\n",
      "ðŸ”§ **Tool Call:** `task_queue_push` with arguments: `{'task_description': 'start calling me Charles'}`\n",
      "---\n",
      "ðŸ”§ **Tool Return:**\n",
      "```\n",
      "Task 'start calling me Charles' was added. Current tasks: [\"start calling me Charles\"]\n",
      "```\n",
      "---\n",
      "ðŸ§  **Reasoning:** Model wants to call `task_queue_push`.\n",
      "ðŸ”§ **Tool Call:** `task_queue_push` with arguments: `{'task_description': 'tell me a haiku about my name'}`\n",
      "---\n",
      "ðŸ”§ **Tool Return:**\n",
      "```\n",
      "Task 'tell me a haiku about my name' was added. Current tasks: [\"start calling me Charles\", \"tell me a haiku about my name\"]\n",
      "```\n",
      "---\n",
      "ðŸ§  **Reasoning:** All tools have been executed. Generating final summary response.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ¤– Agent: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Task list after adding: [\n",
      "  \"start calling me Charles\",\n",
      "  \"tell me a haiku about my name\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ‘¤ User: Okay, please complete your tasks now."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "ðŸ§  **Reasoning:** Model wants to call `task_queue_pop`.\n",
      "ðŸ”§ **Tool Call:** `task_queue_pop` with arguments: `{}`\n",
      "---\n",
      "ðŸ”§ **Tool Return:**\n",
      "```\n",
      "Completed task: 'start calling me Charles'. Remaining tasks: [\"tell me a haiku about my name\"]\n",
      "```\n",
      "---\n",
      "ðŸ§  **Reasoning:** Model wants to call `task_queue_pop`.\n",
      "ðŸ”§ **Tool Call:** `task_queue_pop` with arguments: `{}`\n",
      "---\n",
      "ðŸ”§ **Tool Return:**\n",
      "```\n",
      "Completed task: 'tell me a haiku about my name'. Remaining tasks: []\n",
      "```\n",
      "---\n",
      "ðŸ§  **Reasoning:** All tools have been executed. Generating final summary response.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ðŸ¤– Agent: Charles, I have finished all your requests.  I started by addressing you as Charles as you requested.  Unfortunately, I was unable to generate a haiku about your name because I don't have the functionality to create poetry.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Final task list: []\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Section 3: Custom Task Queue Memory ---\n",
    "print_markdown(\"## Section 3: Custom Task Queue Memory\")\n",
    "\n",
    "task_agent_system_prompt = \"\"\"\n",
    "You are a task-management assistant. Your goal is to manage a list of tasks in your memory.\n",
    "- When a user gives you tasks, use the `task_queue_push` tool for each one.\n",
    "- When a user asks you to perform or complete tasks, use the `task_queue_pop` tool to work through them one by one.\n",
    "- After managing tasks, provide a brief confirmation to the user.\n",
    "- The user's name is Charles. You must always refer to him as Charles.\n",
    "\"\"\"\n",
    "\n",
    "task_agent = GeminiAgent(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=task_agent_system_prompt,\n",
    "    memory_blocks={\"tasks\": []},\n",
    "    tools=[task_queue_push, task_queue_pop] # Pass the simple tool definitions\n",
    ")\n",
    "\n",
    "# The registry maps tool names to their implementations, injecting the agent state\n",
    "task_tool_registry = {\n",
    "    \"task_queue_push\": lambda task_description: _task_queue_push_impl(task_agent, task_description),\n",
    "    \"task_queue_pop\": lambda: _task_queue_pop_impl(task_agent)\n",
    "}\n",
    "\n",
    "print(\"Initial task list:\", task_agent.memory_blocks[\"tasks\"])\n",
    "\n",
    "run_agent_turn(\n",
    "    task_agent,\n",
    "    task_tool_registry,\n",
    "    \"Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks.\"\n",
    ")\n",
    "\n",
    "print(\"Task list after adding:\", json.dumps(task_agent.memory_blocks[\"tasks\"], indent=2))\n",
    "\n",
    "run_agent_turn(\n",
    "    task_agent,\n",
    "    task_tool_registry,\n",
    "    \"Okay, please complete your tasks now.\"\n",
    ")\n",
    "\n",
    "print(\"Final task list:\", task_agent.memory_blocks[\"tasks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
