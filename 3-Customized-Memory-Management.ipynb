{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:grey; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "### Lab 3: Customized Memory Management Management\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI library\n",
    "#!pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "# Import the function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    api_key = get_gemini_api_key()\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")\n",
    "\n",
    "# Create the system prompt file for the task agent\n",
    "with open(\"task_queue_system_prompt.txt\", \"w\") as f:\n",
    "    f.write(\"You are a task-management assistant. Your goal is to manage a list of tasks in your memory. When a user gives you tasks, use the `task_queue_push` tool for each one. When a user asks you to perform or complete tasks, use the `task_queue_pop` tool to work through them one by one. After managing tasks, provide a brief confirmation to the user. The user's name is Charles. You must always refer to him as Charles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core Agent and Tool Logic\n",
    "This section contains the reusable GeminiAgent class, the tool definitions and implementations, and the main run_agent_turn function that handles the interaction loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Class ---\n",
    "class GeminiAgent:\n",
    "    \"\"\"A class to simulate an agent's state and memory.\"\"\"\n",
    "    def __init__(self, name, model_name, system_prompt=\"\", memory_blocks=None, tools=None):\n",
    "        self.id = f\"agent-{uuid.uuid4()}\"\n",
    "        self.name = name\n",
    "        self.memory_blocks = memory_blocks if memory_blocks else {}\n",
    "        self.tools = tools if tools else []\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "    def get_formatted_memory(self):\n",
    "        \"\"\"Formats memory blocks into a string for the system prompt.\"\"\"\n",
    "        if not self.memory_blocks:\n",
    "            return \"\"\n",
    "        formatted_string = \"--- CORE MEMORY ---\\n\"\n",
    "        for label, value in self.memory_blocks.items():\n",
    "            val_str = json.dumps(value) if isinstance(value, list) else str(value)\n",
    "            formatted_string += f\"<{label}>\\n{val_str}\\n</{label}>\\n\"\n",
    "        return formatted_string.strip()\n",
    "\n",
    "# --- Reusable Printing Function ---\n",
    "def print_message(message_type, content):\n",
    "    \"\"\"Prints formatted messages based on their type.\"\"\"\n",
    "    if message_type == \"reasoning\":\n",
    "        print(f\"ðŸ§  Reasoning: {content}\")\n",
    "    elif message_type == \"assistant\":\n",
    "        print(f\"ðŸ¤– Agent: {content}\")\n",
    "    elif message_type == \"tool_call\":\n",
    "        tool_name = content.get(\"name\", \"N/A\")\n",
    "        arguments = content.get(\"arguments\", {})\n",
    "        print(f\"ðŸ”§ Tool Call: {tool_name}\\n{json.dumps(arguments, indent=2)}\")\n",
    "    elif message_type == \"tool_return\":\n",
    "        print(f\"ðŸ”§ Tool Return: {content}\")\n",
    "    elif message_type == \"user\":\n",
    "        print(f\"ðŸ‘¤ User Message: {content}\")\n",
    "    else:\n",
    "        print(content)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "# --- Tool Definitions (for the model) ---\n",
    "def get_agent_id():\n",
    "    \"\"\"Query your agent ID field.\"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_push(task_description: str):\n",
    "    \"\"\"\n",
    "    Push a task to a task queue stored in core memory.\n",
    "    Args:\n",
    "        task_description (str): A description of the next task you must accomplish.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_pop():\n",
    "    \"\"\"Get the next task from the task queue.\"\"\"\n",
    "    pass\n",
    "\n",
    "# --- Tool Implementations (for Python) ---\n",
    "def _get_agent_id_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for getting the agent ID.\"\"\"\n",
    "    return agent.id\n",
    "\n",
    "def _task_queue_push_impl(agent: GeminiAgent, task_description: str):\n",
    "    \"\"\"Implementation for pushing a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not isinstance(agent.memory_blocks[\"tasks\"], list):\n",
    "        agent.memory_blocks[\"tasks\"] = []\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    tasks.append(task_description)\n",
    "    return f\"Task '{task_description}' was added. Current tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "def _task_queue_pop_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for popping a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not agent.memory_blocks[\"tasks\"]:\n",
    "        return \"The task queue is empty.\"\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    popped_task = tasks.pop(0)\n",
    "    return f\"Completed task: '{popped_task}'. Remaining tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "# --- Generic Agent Interaction Loop ---\n",
    "def run_agent_turn(agent, tool_registry, user_message):\n",
    "    \"\"\"Handles a single turn of conversation with an agent, including tool calls.\"\"\"\n",
    "    print_message(\"user\", user_message)\n",
    "    full_prompt = f\"{agent.system_prompt}\\n\\n{agent.get_formatted_memory()}\\n\\n**Task:**\\n{user_message}\"\n",
    "    history = [{'role': 'user', 'parts': [{'text': full_prompt}]}]\n",
    "    \n",
    "    response = agent.model.generate_content(history, tools=agent.tools)\n",
    "    time.sleep(1)\n",
    "    message = response.candidates[0].content\n",
    "    history.append(message)\n",
    "    \n",
    "    last_action_was_tool = False\n",
    "    while any(part.function_call for part in message.parts):\n",
    "        last_action_was_tool = True\n",
    "        tool_response_parts = []\n",
    "        for part in message.parts:\n",
    "            if not part.function_call: continue\n",
    "            fc = part.function_call\n",
    "            tool_name = fc.name\n",
    "            tool_args = dict(fc.args)\n",
    "            print_message(\"reasoning\", f\"Model wants to call `{tool_name}`.\")\n",
    "            print_message(\"tool_call\", {\"name\": tool_name, \"arguments\": tool_args})\n",
    "            result = tool_registry[tool_name](**tool_args)\n",
    "            print_message(\"tool_return\", result)\n",
    "            tool_response_parts.append({\"function_response\": {\"name\": tool_name, \"response\": {\"content\": result}}})\n",
    "        \n",
    "        history.append({\"role\": \"tool\", \"parts\": tool_response_parts})\n",
    "        response = agent.model.generate_content(history, tools=agent.tools)\n",
    "        time.sleep(1)\n",
    "        message = response.candidates[0].content\n",
    "        history.append(message)\n",
    "\n",
    "    if last_action_was_tool:\n",
    "        print_message(\"reasoning\", \"All tools executed. Generating final summary.\")\n",
    "        history.append({'role': 'user', 'parts': [{'text': \"All tasks are complete. Please provide a final, summary response, including any creative content you were asked to generate.\"}]})\n",
    "        final_response = agent.model.generate_content(history)\n",
    "        final_text = final_response.candidates[0].content.parts[0].text\n",
    "    else:\n",
    "        final_text = message.parts[0].text if message.parts else \"Task complete.\"\n",
    "\n",
    "    print_message(\"assistant\", final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Section 1: Memory Blocks\n",
    "This block creates the first agent and demonstrates how to initialize and view its memory_blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All memory blocks:\n",
      "{\n",
      "  \"human\": \"The human's name is Bob the Builder.\",\n",
      "  \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
      "}\n",
      "\n",
      "Formatted memory prompt:\n",
      "--- CORE MEMORY ---\n",
      "<human>\n",
      "The human's name is Bob the Builder.\n",
      "</human>\n",
      "<persona>\n",
      "My name is Sam, the all-knowing sentient AI.\n",
      "</persona>\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create an agent with initial memory ---\n",
    "agent1 = GeminiAgent(\n",
    "    name=\"agent1\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    memory_blocks={\n",
    "        \"human\": \"The human's name is Bob the Builder.\",\n",
    "        \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 2. Accessing memory blocks ---\n",
    "print(\"All memory blocks:\")\n",
    "print(json.dumps(agent1.memory_blocks, indent=2))\n",
    "\n",
    "print(\"\\nFormatted memory prompt:\")\n",
    "print(agent1.get_formatted_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Section 2: Accessing Agent State with Tools\n",
    "Here, we create a second agent and give it the get_agent_id tool to allow it to access its own state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¤ User Message: What is your agent id?\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `get_agent_id`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: get_agent_id\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: agent-989d4399-248e-42da-897a-16e9bc077eb0\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: All tools executed. Generating final summary.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: This conversation focused on retrieving my agent ID.  No creative content generation was requested or performed.  The final response provided the agent ID: agent-989d4399-248e-42da-897a-16e9bc077eb0.\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create an agent with the get_id tool ---\n",
    "agent2 = GeminiAgent(\n",
    "    name=\"agent2\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    tools=[get_agent_id]\n",
    ")\n",
    "\n",
    "# --- 2. Setup the tool registry ---\n",
    "tool_registry_2 = {\n",
    "    \"get_agent_id\": lambda: _get_agent_id_impl(agent2)\n",
    "}\n",
    "\n",
    "# --- 3. Run the agent ---\n",
    "run_agent_turn(\n",
    "    agent=agent2,\n",
    "    tool_registry=tool_registry_2,\n",
    "    user_message=\"What is your agent id?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Section 3: Custom Task Queue Memory\n",
    "This final section creates the more advanced task_agent that uses tools to modify its own memory, creating a simple task queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial task list: []\n",
      "ðŸ‘¤ User Message: Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks.\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_push`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_push\n",
      "{\n",
      "  \"task_description\": \"start calling me Charles\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Task 'start calling me Charles' was added. Current tasks: [\"start calling me Charles\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_push`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_push\n",
      "{\n",
      "  \"task_description\": \"tell me a haiku about my name\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Task 'tell me a haiku about my name' was added. Current tasks: [\"start calling me Charles\", \"tell me a haiku about my name\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: All tools executed. Generating final summary.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: \n",
      "-----------------------------------------------------\n",
      "Task list after adding: [\n",
      "  \"start calling me Charles\",\n",
      "  \"tell me a haiku about my name\"\n",
      "]\n",
      "ðŸ‘¤ User Message: Okay, please complete your tasks now.\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_pop`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_pop\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Completed task: 'start calling me Charles'. Remaining tasks: [\"tell me a haiku about my name\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_pop`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_pop\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Completed task: 'tell me a haiku about my name'. Remaining tasks: []\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: All tools executed. Generating final summary.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: Charles, all tasks are complete.  I was asked to write a haiku about your name.  Unfortunately, I didn't actually generate one because I was focused on following your instructions precisely.  My apologies!  To complete this, I would need additional instructions.\n",
      "\n",
      "-----------------------------------------------------\n",
      "Final task list: []\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create the Task Agent ---\n",
    "task_agent_system_prompt = open(\"task_queue_system_prompt.txt\", \"r\").read()\n",
    "\n",
    "task_agent = GeminiAgent(\n",
    "    name=\"task_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=task_agent_system_prompt,\n",
    "    memory_blocks={\n",
    "        \"tasks\": []\n",
    "    },\n",
    "    tools=[task_queue_push, task_queue_pop]\n",
    ")\n",
    "\n",
    "# --- 2. Setup Tool Registry ---\n",
    "task_tool_registry = {\n",
    "    \"task_queue_push\": lambda task_description: _task_queue_push_impl(task_agent, task_description),\n",
    "    \"task_queue_pop\": lambda: _task_queue_pop_impl(task_agent)\n",
    "}\n",
    "\n",
    "# --- 3. Use the Task Agent ---\n",
    "print(\"Initial task list:\", json.dumps(task_agent.memory_blocks[\"tasks\"]))\n",
    "\n",
    "# Add two tasks\n",
    "run_agent_turn(\n",
    "    agent=task_agent,\n",
    "    tool_registry=task_tool_registry,\n",
    "    user_message=\"Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks.\"\n",
    ")\n",
    "\n",
    "print(\"Task list after adding:\", json.dumps(task_agent.memory_blocks[\"tasks\"], indent=2))\n",
    "\n",
    "# Complete the tasks\n",
    "run_agent_turn(\n",
    "    agent=task_agent,\n",
    "    tool_registry=task_tool_registry,\n",
    "    user_message=\"Okay, please complete your tasks now.\"\n",
    ")\n",
    "\n",
    "print(\"Final task list:\", json.dumps(task_agent.memory_blocks[\"tasks\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
