{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:grey; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "### Lab 3: Customized Memory Management Management\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI library\n",
    "#!pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "# Import the function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    api_key = get_gemini_api_key()\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")\n",
    "\n",
    "# Create the system prompt file for the task agent\n",
    "with open(\"task_queue_system_prompt.txt\", \"w\") as f:\n",
    "    f.write(\"You are a task-management assistant. Your goal is to manage a list of tasks in your memory. When a user gives you tasks, use the `task_queue_push` tool for each one. When a user asks you to perform or complete tasks, use the `task_queue_pop` tool to work through them one by one. After managing tasks, provide a brief confirmation to the user. The user's name is Charles. You must always refer to him as Charles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core Agent and Tool Logic\n",
    "This section contains the reusable GeminiAgent class, the tool definitions and implementations, and the main run_agent_turn function that handles the interaction loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Class ---\n",
    "class GeminiAgent:\n",
    "    \"\"\"A class to simulate an agent's state and memory.\"\"\"\n",
    "    def __init__(self, name, model_name, system_prompt=\"\", memory_blocks=None, tools=None):\n",
    "        self.id = f\"agent-{uuid.uuid4()}\"\n",
    "        self.name = name\n",
    "        self.memory_blocks = memory_blocks if memory_blocks else {}\n",
    "        self.tools = tools if tools else []\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "    def get_formatted_memory(self):\n",
    "        \"\"\"Formats memory blocks into a string for the system prompt.\"\"\"\n",
    "        if not self.memory_blocks:\n",
    "            return \"\"\n",
    "        formatted_string = \"--- CORE MEMORY ---\\n\"\n",
    "        for label, value in self.memory_blocks.items():\n",
    "            val_str = json.dumps(value) if isinstance(value, list) else str(value)\n",
    "            formatted_string += f\"<{label}>\\n{val_str}\\n</{label}>\\n\"\n",
    "        return formatted_string.strip()\n",
    "\n",
    "# --- Reusable Printing Function ---\n",
    "def print_message(message_type, content):\n",
    "    \"\"\"Prints formatted messages based on their type.\"\"\"\n",
    "    if message_type == \"reasoning\":\n",
    "        print(f\"ðŸ§  Reasoning: {content}\")\n",
    "    elif message_type == \"assistant\":\n",
    "        print(f\"ðŸ¤– Agent: {content}\")\n",
    "    elif message_type == \"tool_call\":\n",
    "        tool_name = content.get(\"name\", \"N/A\")\n",
    "        arguments = content.get(\"arguments\", {})\n",
    "        print(f\"ðŸ”§ Tool Call: {tool_name}\\n{json.dumps(arguments, indent=2)}\")\n",
    "    elif message_type == \"tool_return\":\n",
    "        print(f\"ðŸ”§ Tool Return: {content}\")\n",
    "    elif message_type == \"user\":\n",
    "        print(f\"ðŸ‘¤ User Message: {content}\")\n",
    "    else:\n",
    "        print(content)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "# --- Tool Definitions (for the model) ---\n",
    "def get_agent_id():\n",
    "    \"\"\"Query your agent ID field.\"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_push(task_description: str):\n",
    "    \"\"\"\n",
    "    Push a task to a task queue stored in core memory.\n",
    "    Args:\n",
    "        task_description (str): A description of the next task you must accomplish.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def task_queue_pop():\n",
    "    \"\"\"Get the next task from the task queue.\"\"\"\n",
    "    pass\n",
    "\n",
    "# --- Tool Implementations (for Python) ---\n",
    "def _get_agent_id_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for getting the agent ID.\"\"\"\n",
    "    return agent.id\n",
    "\n",
    "def _task_queue_push_impl(agent: GeminiAgent, task_description: str):\n",
    "    \"\"\"Implementation for pushing a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not isinstance(agent.memory_blocks[\"tasks\"], list):\n",
    "        agent.memory_blocks[\"tasks\"] = []\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    tasks.append(task_description)\n",
    "    return f\"Task '{task_description}' was added. Current tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "def _task_queue_pop_impl(agent: GeminiAgent):\n",
    "    \"\"\"Implementation for popping a task.\"\"\"\n",
    "    if \"tasks\" not in agent.memory_blocks or not agent.memory_blocks[\"tasks\"]:\n",
    "        return \"The task queue is empty.\"\n",
    "    tasks = agent.memory_blocks[\"tasks\"]\n",
    "    popped_task = tasks.pop(0)\n",
    "    return f\"Completed task: '{popped_task}'. Remaining tasks: {json.dumps(tasks)}\"\n",
    "\n",
    "# --- Generic Agent Interaction Loop ---\n",
    "def run_agent_turn(agent, tool_registry, user_message):\n",
    "    \"\"\"Handles a single turn of conversation with an agent, including tool calls.\"\"\"\n",
    "    print_message(\"user\", user_message)\n",
    "    full_prompt = f\"{agent.system_prompt}\\n\\n{agent.get_formatted_memory()}\\n\\n**Task:**\\n{user_message}\"\n",
    "    history = [{'role': 'user', 'parts': [{'text': full_prompt}]}]\n",
    "    \n",
    "    response = agent.model.generate_content(history, tools=agent.tools)\n",
    "    time.sleep(1)\n",
    "    message = response.candidates[0].content\n",
    "    history.append(message)\n",
    "    \n",
    "    last_action_was_tool = False\n",
    "    while any(part.function_call for part in message.parts):\n",
    "        last_action_was_tool = True\n",
    "        tool_response_parts = []\n",
    "        for part in message.parts:\n",
    "            if not part.function_call: continue\n",
    "            fc = part.function_call\n",
    "            tool_name = fc.name\n",
    "            tool_args = dict(fc.args)\n",
    "            print_message(\"reasoning\", f\"Model wants to call `{tool_name}`.\")\n",
    "            print_message(\"tool_call\", {\"name\": tool_name, \"arguments\": tool_args})\n",
    "            result = tool_registry[tool_name](**tool_args)\n",
    "            print_message(\"tool_return\", result)\n",
    "            tool_response_parts.append({\"function_response\": {\"name\": tool_name, \"response\": {\"content\": result}}})\n",
    "        \n",
    "        history.append({\"role\": \"tool\", \"parts\": tool_response_parts})\n",
    "        response = agent.model.generate_content(history, tools=agent.tools)\n",
    "        time.sleep(1)\n",
    "        message = response.candidates[0].content\n",
    "        history.append(message)\n",
    "\n",
    "    if last_action_was_tool:\n",
    "        print_message(\"reasoning\", \"All tools executed. Generating final summary.\")\n",
    "        history.append({'role': 'user', 'parts': [{'text': \"All tasks are complete. Please provide a final, summary response, including any creative content you were asked to generate.\"}]})\n",
    "        final_response = agent.model.generate_content(history)\n",
    "        final_text = final_response.candidates[0].content.parts[0].text\n",
    "    else:\n",
    "        final_text = message.parts[0].text if message.parts else \"Task complete.\"\n",
    "\n",
    "    print_message(\"assistant\", final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Section 1: Memory Blocks\n",
    "This block creates the first agent and demonstrates how to initialize and view its memory_blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All memory blocks:\n",
      "{\n",
      "  \"human\": \"The human's name is Bob the Builder.\",\n",
      "  \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
      "}\n",
      "\n",
      "Formatted memory prompt:\n",
      "--- CORE MEMORY ---\n",
      "<human>\n",
      "The human's name is Bob the Builder.\n",
      "</human>\n",
      "<persona>\n",
      "My name is Sam, the all-knowing sentient AI.\n",
      "</persona>\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create an agent with initial memory ---\n",
    "agent1 = GeminiAgent(\n",
    "    name=\"agent1\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    memory_blocks={\n",
    "        \"human\": \"The human's name is Bob the Builder.\",\n",
    "        \"persona\": \"My name is Sam, the all-knowing sentient AI.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 2. Accessing memory blocks ---\n",
    "print(\"All memory blocks:\")\n",
    "print(json.dumps(agent1.memory_blocks, indent=2))\n",
    "\n",
    "print(\"\\nFormatted memory prompt:\")\n",
    "print(agent1.get_formatted_memory())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Section 2: Accessing Agent State with Tools\n",
    "Here, we create a second agent and give it the get_agent_id tool to allow it to access its own state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¤ User Message: What is your agent id?\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `get_agent_id`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: get_agent_id\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: agent-c5534ed9-1ca1-45fe-8d66-9ab8ece98bab\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 11\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m tool_registry_2 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_agent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: _get_agent_id_impl(agent2)\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# --- 3. Run the agent ---\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mrun_agent_turn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_registry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_registry_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is your agent id?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 110\u001b[0m, in \u001b[0;36mrun_agent_turn\u001b[0;34m(agent, tool_registry, user_message)\u001b[0m\n\u001b[1;32m    107\u001b[0m     tool_response_parts\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_response\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: result}}})\n\u001b[1;32m    109\u001b[0m history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_response_parts})\n\u001b[0;32m--> 110\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    112\u001b[0m message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    210\u001b[0m         error_list,\n\u001b[1;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    212\u001b[0m         original_timeout,\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 11\n}\n]"
     ]
    }
   ],
   "source": [
    "# --- 1. Create an agent with the get_id tool ---\n",
    "agent2 = GeminiAgent(\n",
    "    name=\"agent2\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    tools=[get_agent_id]\n",
    ")\n",
    "\n",
    "# --- 2. Setup the tool registry ---\n",
    "tool_registry_2 = {\n",
    "    \"get_agent_id\": lambda: _get_agent_id_impl(agent2)\n",
    "}\n",
    "\n",
    "# --- 3. Run the agent ---\n",
    "run_agent_turn(\n",
    "    agent=agent2,\n",
    "    tool_registry=tool_registry_2,\n",
    "    user_message=\"What is your agent id?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Section 3: Custom Task Queue Memory\n",
    "This final section creates the more advanced task_agent that uses tools to modify its own memory, creating a simple task queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial task list: []\n",
      "ðŸ‘¤ User Message: Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks.\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_push`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_push\n",
      "{\n",
      "  \"task_description\": \"start calling me Charles\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Task 'start calling me Charles' was added. Current tasks: [\"start calling me Charles\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_push`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_push\n",
      "{\n",
      "  \"task_description\": \"tell me a haiku about my name\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Task 'tell me a haiku about my name' was added. Current tasks: [\"start calling me Charles\", \"tell me a haiku about my name\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: All tools executed. Generating final summary.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: \n",
      "-----------------------------------------------------\n",
      "Task list after adding: [\n",
      "  \"start calling me Charles\",\n",
      "  \"tell me a haiku about my name\"\n",
      "]\n",
      "ðŸ‘¤ User Message: Okay, please complete your tasks now.\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_pop`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_pop\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Completed task: 'start calling me Charles'. Remaining tasks: [\"tell me a haiku about my name\"]\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: Model wants to call `task_queue_pop`.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: task_queue_pop\n",
      "{}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Completed task: 'tell me a haiku about my name'. Remaining tasks: []\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: All tools executed. Generating final summary.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: Charles, all tasks are complete.  I was asked to write a haiku about your name.  Unfortunately, I didn't actually generate one because I was focused on following your instructions precisely.  My apologies!  To complete this, I would need additional instructions.\n",
      "\n",
      "-----------------------------------------------------\n",
      "Final task list: []\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create the Task Agent ---\n",
    "task_agent_system_prompt = open(\"task_queue_system_prompt.txt\", \"r\").read()\n",
    "\n",
    "task_agent = GeminiAgent(\n",
    "    name=\"task_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=task_agent_system_prompt,\n",
    "    memory_blocks={\n",
    "        \"tasks\": []\n",
    "    },\n",
    "    tools=[task_queue_push, task_queue_pop]\n",
    ")\n",
    "\n",
    "# --- 2. Setup Tool Registry ---\n",
    "task_tool_registry = {\n",
    "    \"task_queue_push\": lambda task_description: _task_queue_push_impl(task_agent, task_description),\n",
    "    \"task_queue_pop\": lambda: _task_queue_pop_impl(task_agent)\n",
    "}\n",
    "\n",
    "# --- 3. Use the Task Agent ---\n",
    "print(\"Initial task list:\", json.dumps(task_agent.memory_blocks[\"tasks\"]))\n",
    "\n",
    "# Add two tasks\n",
    "run_agent_turn(\n",
    "    agent=task_agent,\n",
    "    tool_registry=task_tool_registry,\n",
    "    user_message=\"Add 'start calling me Charles' and 'tell me a haiku about my name' as two separate tasks.\"\n",
    ")\n",
    "\n",
    "print(\"Task list after adding:\", json.dumps(task_agent.memory_blocks[\"tasks\"], indent=2))\n",
    "\n",
    "# Complete the tasks\n",
    "run_agent_turn(\n",
    "    agent=task_agent,\n",
    "    tool_registry=task_tool_registry,\n",
    "    user_message=\"Okay, please complete your tasks now.\"\n",
    ")\n",
    "\n",
    "print(\"Final task list:\", json.dumps(task_agent.memory_blocks[\"tasks\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
