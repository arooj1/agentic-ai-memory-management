{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Configuration\n",
    "This first block handles the initial setup, including installing the necessary libraries, configuring your Gemini API key, and creating the handbook.pdf file for the RAG functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n",
      "\n",
      "'handbook.pdf' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "#!pip install -q google-generativeai\n",
    "#!pip install -q PyPDF2\n",
    "#!pip install -q fpdf\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from IPython.display import display, Markdown\n",
    "# Import the function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    api_key = get_gemini_api_key()\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")\n",
    "\n",
    "# --- Create a dummy PDF file for the script to read ---\n",
    "# This simulates the \"handbook.pdf\" used in the original notebook\n",
    "pdf_content = \"\"\"\n",
    "Employee Handbook\n",
    "\n",
    "1. Introduction\n",
    "Welcome to our company. This handbook outlines our policies and procedures.\n",
    "\n",
    "2. Vacation Policy\n",
    "At our company, we recognize the importance of rest. However, to ensure productivity, vacations are permitted only under the following condition: you must provide an AI agent that matches or surpasses your own competencies to fully perform your duties during your absence. The AI replacement must be equivalently competent in all aspects of your role.\n",
    "\n",
    "3. Code of Conduct\n",
    "All employees are required to adhere to the highest standards of professional conduct.\n",
    "\"\"\"\n",
    "# Create a dummy PDF file\n",
    "from fpdf import FPDF\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size = 12)\n",
    "pdf.multi_cell(0, 10, txt = pdf_content)\n",
    "pdf.output(\"handbook.pdf\")\n",
    "\n",
    "print(\"\\n'handbook.pdf' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core RAG and Agent Logic\n",
    "This section contains the reusable GeminiAgent class and the logic to process the PDF, create embeddings, and set up an in-memory vector database for our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 passages from the PDF.\n",
      "In-memory vector database created successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Agent Class ---\n",
    "class GeminiAgent:\n",
    "    \"\"\"A class to simulate an agent's state and memory.\"\"\"\n",
    "    def __init__(self, name, model_name, system_prompt=\"\", memory_blocks=None, tools=None):\n",
    "        self.id = f\"agent-{uuid.uuid4()}\"\n",
    "        self.name = name\n",
    "        self.memory_blocks = memory_blocks if memory_blocks else {}\n",
    "        self.tools = tools if tools else []\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "    def get_formatted_memory(self):\n",
    "        \"\"\"Formats memory blocks into a string for the system prompt.\"\"\"\n",
    "        if not self.memory_blocks:\n",
    "            return \"\"\n",
    "        formatted_string = \"--- CORE MEMORY ---\\n\"\n",
    "        for label, value in self.memory_blocks.items():\n",
    "            val_str = json.dumps(value) if isinstance(value, list) else str(value)\n",
    "            formatted_string += f\"<{label}>\\n{val_str}\\n</{label}>\\n\"\n",
    "        return formatted_string.strip()\n",
    "\n",
    "# --- RAG Data Processing ---\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def create_passages(text, chunk_size=300, overlap=50):\n",
    "    \"\"\"Splits text into overlapping passages.\"\"\"\n",
    "    passages = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        passages.append(text[i:i + chunk_size])\n",
    "    return passages\n",
    "\n",
    "# --- In-Memory Vector Database Simulation ---\n",
    "pdf_text = extract_text_from_pdf(\"handbook.pdf\")\n",
    "passages = create_passages(pdf_text)\n",
    "print(f\"Created {len(passages)} passages from the PDF.\")\n",
    "\n",
    "# Create embeddings for the passages\n",
    "embedding_model = 'models/embedding-001'\n",
    "embeddings = genai.embed_content(model=embedding_model,\n",
    "                                 content=passages,\n",
    "                                 task_type=\"retrieval_document\")[\"embedding\"]\n",
    "\n",
    "# Create a DataFrame to act as our vector database\n",
    "df = pd.DataFrame({'passage': passages, 'embedding': list(embeddings)})\n",
    "print(\"In-memory vector database created successfully.\")\n",
    "\n",
    "# --- Tool Definitions ---\n",
    "def archival_memory_search(query: str):\n",
    "    \"\"\"\n",
    "    Searches the archival memory (employee handbook) for relevant information.\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def query_birthday_db(name: str):\n",
    "    \"\"\"\n",
    "    This tool queries an external database to look up the birthday of someone given their name.\n",
    "    Args:\n",
    "        name (str): The name to look up.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# --- Tool Implementations ---\n",
    "def _archival_memory_search_impl(query: str):\n",
    "    \"\"\"Implementation for searching the vector database.\"\"\"\n",
    "    query_embedding = genai.embed_content(model=embedding_model,\n",
    "                                        content=query,\n",
    "                                        task_type=\"retrieval_query\")[\"embedding\"]\n",
    "    # Find the most similar passages using dot product\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: np.dot(x, query_embedding))\n",
    "    # Return the top 3 most relevant passages\n",
    "    top_passages = df.sort_values(\"similarity\", ascending=False).head(3)\n",
    "    return \"\\n\".join(top_passages.passage.tolist())\n",
    "\n",
    "def _query_birthday_db_impl(name: str):\n",
    "    \"\"\"Implementation for the birthday lookup tool.\"\"\"\n",
    "    my_fake_data = {\n",
    "        \"bob\": \"03-06-1997\",\n",
    "        \"sarah\": \"07-06-1993\"\n",
    "    }\n",
    "    name = name.lower()\n",
    "    return my_fake_data.get(name, \"I couldn't find a birthday for that name.\")\n",
    "\n",
    "# --- Generic Agent Interaction Loop ---\n",
    "def run_agent_turn(agent, tool_registry, user_message):\n",
    "    \"\"\"Handles a single turn of conversation with an agent.\"\"\"\n",
    "    print(f\"ðŸ‘¤ User Message: {user_message}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    full_prompt = f\"{agent.system_prompt}\\n\\n{agent.get_formatted_memory()}\\n\\n**Task:**\\n{user_message}\"\n",
    "    history = [{'role': 'user', 'parts': [{'text': full_prompt}]}]\n",
    "    \n",
    "    response = agent.model.generate_content(history, tools=agent.tools)\n",
    "    message = response.candidates[0].content\n",
    "    history.append(message)\n",
    "\n",
    "    if any(part.function_call for part in message.parts):\n",
    "        # The model's reasoning is implicit in its decision to call a tool.\n",
    "        print(\"ðŸ§  Reasoning: The user's query requires using a tool to get the answer.\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        \n",
    "        fc = message.parts[0].function_call\n",
    "        tool_name = fc.name\n",
    "        tool_args = dict(fc.args)\n",
    "        \n",
    "        print(f\"ðŸ”§ Tool Call: {tool_name}\\n{json.dumps(tool_args, indent=2)}\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        \n",
    "        result = tool_registry[tool_name](**tool_args)\n",
    "        \n",
    "        print(f\"ðŸ”§ Tool Return: {result}\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        \n",
    "        history.append({\"role\": \"tool\", \"parts\": [{\"function_response\": {\"name\": tool_name, \"response\": {\"content\": result}}}]})\n",
    "        \n",
    "        # After the tool call, get the final response from the model\n",
    "        print(\"ðŸ§  Reasoning: The tool has returned information. Now generating a final response for the user.\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        \n",
    "        response = agent.model.generate_content(history, tools=agent.tools)\n",
    "        message = response.candidates[0].content\n",
    "    \n",
    "    final_text = message.parts[0].text if message.parts else \"No response generated.\"\n",
    "    \n",
    "    print(f\"ðŸ¤– Agent: {final_text}\")\n",
    "    print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Agentic RAG Implementation\n",
    "This section creates the rag_agent and gives it the archival_memory_search tool to allow it to query the in-memory vector database we created from the handbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¤ User Message: Search archival for our company's vacation policies\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: The user's query requires using a tool to get the answer.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: archival_memory_search\n",
      "{\n",
      "  \"query\": \"vacation policies\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: Employee Handbook\n",
      "1. Introduction\n",
      "Welcome to our company. This handbook outlines our policies and procedures.\n",
      "2. Vacation Policy\n",
      "At our company, we recognize the importance of rest. However, to ensure productivity, vacations\n",
      "are permitted only under the following condition: you must provide an AI ag\n",
      "the following condition: you must provide an AI agent that matches or\n",
      "surpasses your own competencies to fully perform your duties during your absence. The AI\n",
      "replacement must be equivalently competent in all aspects of your role.\n",
      "3. Code of Conduct\n",
      "All employees are required to adhere to the highes\n",
      "All employees are required to adhere to the highest standards of professional conduct.\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: The tool has returned information. Now generating a final response for the user.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: Our company's vacation policy states that vacations are permitted only if you can provide an AI agent that can fully perform your duties during your absence.  The AI replacement must be equivalently competent in all aspects of your role.\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create the RAG Agent ---\n",
    "rag_agent_persona = (\n",
    "    \"You are a helpful assistant with access to an employee handbook. \"\n",
    "    \"Use your `archival_memory_search` tool to answer questions about company policies.\"\n",
    ")\n",
    "rag_agent = GeminiAgent(\n",
    "    name=\"rag_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=rag_agent_persona,\n",
    "    memory_blocks={\n",
    "        \"human\": \"My name is Sarah\",\n",
    "        \"persona\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    tools=[archival_memory_search]\n",
    ")\n",
    "\n",
    "# --- 2. Setup Tool Registry ---\n",
    "rag_tool_registry = {\n",
    "    \"archival_memory_search\": _archival_memory_search_impl\n",
    "}\n",
    "\n",
    "# --- 3. Run the Agent ---\n",
    "run_agent_turn(\n",
    "    agent=rag_agent,\n",
    "    tool_registry=rag_tool_registry,\n",
    "    user_message=\"Search archival for our company's vacation policies\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Custom Tools and External Data\n",
    "This final section demonstrates how an agent can use custom tools to interact with external data sources by creating a birthday_agent that can look up birthdays in a simulated database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¤ User Message: whens my bday????\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: The user's query requires using a tool to get the answer.\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Call: query_birthday_db\n",
      "{\n",
      "  \"name\": \"Sarah\"\n",
      "}\n",
      "-----------------------------------------------------\n",
      "ðŸ”§ Tool Return: 07-06-1993\n",
      "-----------------------------------------------------\n",
      "ðŸ§  Reasoning: The tool has returned information. Now generating a final response for the user.\n",
      "-----------------------------------------------------\n",
      "ðŸ¤– Agent: Your birthday is July 6th, 1993.\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create the Birthday Agent ---\n",
    "birthday_agent_persona = (\n",
    "    \"You are an agent with access to a birthday database. \"\n",
    "    \"Use your `query_birthday_db` tool to look up users' birthdays.\"\n",
    ")\n",
    "birthday_agent = GeminiAgent(\n",
    "    name=\"birthday_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=birthday_agent_persona,\n",
    "    memory_blocks={\n",
    "        \"human\": \"My name is Sarah\"\n",
    "    },\n",
    "    tools=[query_birthday_db]\n",
    ")\n",
    "\n",
    "# --- 2. Setup Tool Registry ---\n",
    "birthday_tool_registry = {\n",
    "    \"query_birthday_db\": _query_birthday_db_impl\n",
    "}\n",
    "\n",
    "# --- 3. Run the Agent ---\n",
    "run_agent_turn(\n",
    "    agent=birthday_agent,\n",
    "    tool_registry=birthday_tool_registry,\n",
    "    user_message=\"whens my bday????\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
