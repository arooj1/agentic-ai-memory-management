{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:grey; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "### Lab 5: Orchestrating Agents with MemGPT\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Configuration\n",
    "This first block handles the initial setup, including \n",
    "- installing the library and \n",
    "- configuring your Gemini API key using the helper.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI library\n",
    "#!pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "# Import the function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    api_key = get_gemini_api_key()\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")\n",
    "\n",
    "# --- Resume Files ---\n",
    "# Create dummy resume files for the script to read\n",
    "with open(\"tony_stark.txt\", \"w\") as f:\n",
    "    f.write(\"Tony Stark: Genius, billionaire, playboy, philanthropist. Expert in robotics and AI. Built the Iron Man suit. Strong software engineering skills.\")\n",
    "\n",
    "with open(\"spongebob_squarepants.txt\", \"w\") as f:\n",
    "    f.write(\"Spongebob Squarepants: Fry cook at the Krusty Krab. Enthusiastic and dedicated, but lacks technical skills in software engineering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core Agent and Orchestration Logic\n",
    "This section contains \n",
    "- the reusable GeminiAgent class and \n",
    "- the new run_orchestration function, which will manage the interactions between our different agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Class ---\n",
    "class GeminiAgent:\n",
    "    \"\"\"A class to simulate an agent's state and memory.\"\"\"\n",
    "    def __init__(self, name, model_name, system_prompt=\"\", memory_blocks=None, tools=None):\n",
    "        self.id = f\"agent-{uuid.uuid4()}\"\n",
    "        self.name = name\n",
    "        self.memory_blocks = memory_blocks if memory_blocks else {}\n",
    "        self.tools = tools if tools else []\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "    def get_formatted_memory(self):\n",
    "        \"\"\"Formats memory blocks into a string for the system prompt.\"\"\"\n",
    "        if not self.memory_blocks:\n",
    "            return \"\"\n",
    "        formatted_string = \"--- CORE MEMORY ---\\n\"\n",
    "        for label, value in self.memory_blocks.items():\n",
    "            val_str = json.dumps(value) if isinstance(value, list) else str(value)\n",
    "            formatted_string += f\"<{label}>\\n{val_str}\\n</{label}>\\n\"\n",
    "        return formatted_string.strip()\n",
    "\n",
    "# --- Tool Definitions (for the model) ---\n",
    "def draft_candidate_email(content: str):\n",
    "    \"\"\"\n",
    "    Draft an email to reach out to a candidate.\n",
    "    Args:\n",
    "        content (str): Content of the email.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def reject(candidate_name: str):\n",
    "    \"\"\"\n",
    "    Reject a candidate.\n",
    "    Args:\n",
    "        candidate_name (str): The name of the candidate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# --- Tool Implementations (for Python) ---\n",
    "def _draft_candidate_email_impl(content: str):\n",
    "    \"\"\"Implementation for drafting an email.\"\"\"\n",
    "    print(f\"📧 **Email Drafted:**\\n---\\n{content}\\n---\\n\")\n",
    "    return f\"Email draft completed.\"\n",
    "\n",
    "def _reject_impl(candidate_name: str):\n",
    "    \"\"\"Implementation for rejecting a candidate.\"\"\"\n",
    "    print(f\"🚫 **Candidate Rejected:** {candidate_name}\\n\")\n",
    "    return f\"Candidate {candidate_name} has been rejected.\"\n",
    "\n",
    "# --- Orchestration Logic ---\n",
    "def run_orchestration(initial_agent, agents_map, tool_registries, initial_message):\n",
    "    \"\"\"Manages a multi-agent workflow.\"\"\"\n",
    "    print_markdown(f\"### 👤 User: {initial_message}\")\n",
    "    print(\"---\")\n",
    "\n",
    "    current_agent = initial_agent\n",
    "    message_to_agent = initial_message\n",
    "    history = []\n",
    "\n",
    "    for i in range(5): # Limit loops to prevent infinite cycles\n",
    "        print_markdown(f\"#### ➡️ Turn {i+1}: Passing control to `{current_agent.name}`\")\n",
    "        \n",
    "        full_prompt = f\"{current_agent.system_prompt}\\n\\n{current_agent.get_formatted_memory()}\\n\\n**New Task:**\\n{message_to_agent}\"\n",
    "        history.append({'role': 'user', 'parts': [{'text': full_prompt}]})\n",
    "\n",
    "        response = current_agent.model.generate_content(history, tools=current_agent.tools)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Safety check for empty or blocked responses\n",
    "        if not response.candidates:\n",
    "            print_markdown(f\"### 🤖 Agent ({current_agent.name}): No response was generated. This might be due to safety settings.\")\n",
    "            print_markdown(\"#### ✅ Orchestration Complete\")\n",
    "            return\n",
    "\n",
    "        message = response.candidates[0].content\n",
    "        history.append(message)\n",
    "\n",
    "        # Handle tool calls\n",
    "        if any(part.function_call for part in message.parts):\n",
    "            tool_response_parts = []\n",
    "            for part in message.parts:\n",
    "                if not part.function_call: continue\n",
    "                fc = part.function_call\n",
    "                tool_name = fc.name\n",
    "                tool_args = dict(fc.args)\n",
    "                print(f\"🧠 **Reasoning ({current_agent.name}):** Model wants to call `{tool_name}`.\")\n",
    "                print(f\"🔧 **Tool Call ({current_agent.name}):** `{tool_name}` with arguments: `{tool_args}`\\n\" + \"---\")\n",
    "                \n",
    "                result = tool_registries[current_agent.name][tool_name](**tool_args)\n",
    "                tool_response_parts.append({\"function_response\": {\"name\": tool_name, \"response\": {\"content\": result}}})\n",
    "            \n",
    "            history.append({\"role\": \"tool\", \"parts\": tool_response_parts})\n",
    "            response = current_agent.model.generate_content(history, tools=current_agent.tools)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            if not response.candidates:\n",
    "                print_markdown(f\"### 🤖 Agent ({current_agent.name}): No response was generated after a tool call. This might be due to safety settings.\")\n",
    "                print_markdown(\"#### ✅ Orchestration Complete\")\n",
    "                return\n",
    "\n",
    "            message = response.candidates[0].content\n",
    "            history.append(message)\n",
    "\n",
    "        # Safely access the final text\n",
    "        final_text = message.parts[0].text if message.parts else \"The agent did not provide a text response.\"\n",
    "        print_markdown(f\"### 🤖 Agent ({current_agent.name}): {final_text}\")\n",
    "\n",
    "        # Check for handoff instructions\n",
    "        if \"NEXT_AGENT:\" in final_text:\n",
    "            parts = final_text.split(\"MESSAGE:\", 1)\n",
    "            next_agent_name = parts[0].replace(\"NEXT_AGENT:\", \"\").strip()\n",
    "            message_to_agent = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "            current_agent = agents_map[next_agent_name]\n",
    "        else:\n",
    "            print_markdown(\"#### ✅ Orchestration Complete\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE - Sample Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemini API configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI library\n",
    "#!pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "# Import the function from your helper file\n",
    "from helper import get_gemini_api_key\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Prints text as markdown in a notebook.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    api_key = get_gemini_api_key()\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is missing. Please ensure your helper.py file returns a valid key.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"\\nGemini API configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during configuration: {e}\")\n",
    "\n",
    "# --- Resume Files ---\n",
    "# Create dummy resume files for the script to read\n",
    "with open(\"tony_stark.txt\", \"w\") as f:\n",
    "    f.write(\"Tony Stark: Genius, billionaire, playboy, philanthropist. Expert in robotics and AI. Built the Iron Man suit. Strong software engineering skills.\")\n",
    "\n",
    "with open(\"spongebob_squarepants.txt\", \"w\") as f:\n",
    "    f.write(\"Spongebob Squarepants: Fry cook at the Krusty Krab. Enthusiastic and dedicated, but lacks technical skills in software engineering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-Agent Orchestration\n",
    "This section \n",
    "- sets up the two agents (eval_agent and outreach_agent), \n",
    "- defines their shared memory, and \n",
    "- runs the orchestration to evaluate a candidate's resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 👤 User: Evaluate this resume: Tony Stark: Genius, billionaire, playboy, philanthropist. Expert in robotics and AI. Built the Iron Man suit. Strong software engineering skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### ➡️ Turn 1: Passing control to `eval_agent`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 🤖 Agent (eval_agent): The agent did not provide a text response."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### ✅ Orchestration Complete"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "--- \n",
       "### Demonstrating Shared Memory Update"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original company name in eval_agent's memory: 'The company is called AgentOS and is building AI tools to make it easier to create and deploy LLM agents.'\n",
      "Updated company name in eval_agent's memory: 'The company has rebranded to Letta'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Shared Memory ---\n",
    "# This dictionary will be passed to both agents to simulate a shared memory block.\n",
    "shared_memory = {\n",
    "    \"company\": \"The company is called AgentOS and is building AI tools to make it easier to create and deploy LLM agents.\"\n",
    "}\n",
    "\n",
    "# --- 2. Create Outreach Agent ---\n",
    "outreach_persona = (\n",
    "    \"You are responsible for drafting emails on behalf of a company using the `draft_candidate_email` tool. \"\n",
    "    \"You will receive instructions to draft emails for specific candidates.\"\n",
    ")\n",
    "outreach_agent = GeminiAgent(\n",
    "    name=\"outreach_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=outreach_persona,\n",
    "    memory_blocks=shared_memory,\n",
    "    tools=[draft_candidate_email]\n",
    ")\n",
    "\n",
    "# --- 3. Create Evaluation Agent ---\n",
    "skills = \"Front-end (React, Typescript) or software engineering skills\"\n",
    "eval_persona = (\n",
    "    f\"You are responsible for evaluating candidates based on their resumes. Ideal candidates have skills in: {skills}. \"\n",
    "    \"You have two choices: \\n\"\n",
    "    \"1. If the candidate is a bad fit, use your `reject` tool. \\n\"\n",
    "    \"2. If the candidate is a strong fit, you MUST hand them off to the `outreach_agent`. To do this, respond with the exact format: 'NEXT_AGENT: outreach_agent MESSAGE: [Your message to the outreach agent, e.g., 'Draft an email for candidate X']'\"\n",
    ")\n",
    "eval_agent = GeminiAgent(\n",
    "    name=\"eval_agent\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_prompt=eval_persona,\n",
    "    memory_blocks=shared_memory,\n",
    "    tools=[reject]\n",
    ")\n",
    "\n",
    "# --- 4. Setup Registries and Agent Map ---\n",
    "agents_map = {\n",
    "    \"eval_agent\": eval_agent,\n",
    "    \"outreach_agent\": outreach_agent\n",
    "}\n",
    "tool_registries = {\n",
    "    \"eval_agent\": {\"reject\": _reject_impl},\n",
    "    \"outreach_agent\": {\"draft_candidate_email\": _draft_candidate_email_impl}\n",
    "}\n",
    "\n",
    "# --- 5. Run the Orchestration ---\n",
    "resume = open(\"tony_stark.txt\", \"r\").read()\n",
    "run_orchestration(\n",
    "    initial_agent=eval_agent,\n",
    "    agents_map=agents_map,\n",
    "    tool_registries=tool_registries,\n",
    "    initial_message=f\"Evaluate this resume: {resume}\"\n",
    ")\n",
    "\n",
    "# --- 6. Demonstrate Shared Memory Update ---\n",
    "print_markdown(\"\\n--- \\n### Demonstrating Shared Memory Update\")\n",
    "print(f\"Original company name in eval_agent's memory: '{eval_agent.memory_blocks['company']}'\")\n",
    "shared_memory['company'] = \"The company has rebranded to Letta\"\n",
    "print(f\"Updated company name in eval_agent's memory: '{eval_agent.memory_blocks['company']}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simulating Agent Groups (Round-Robin)\n",
    "This final section simulates \n",
    "- the \"agent group\" concept by creating a simple round-robin orchestrator that passes a message from one agent to the next in a predefined sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 👤 User: Evaluate this resume: Spongebob Squarepants: Fry cook at the Krusty Krab. Enthusiastic and dedicated, but lacks technical skills in software engineering."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### ➡️ Turn 1: Passing control to `eval_agent` (Round-Robin)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 **Tool Call (eval_agent):** `reject` with arguments: `{'candidate_name': 'Spongebob Squarepants'}`\n",
      "---\n",
      "🚫 **Candidate Rejected:** Spongebob Squarepants\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🤖 Agent (eval_agent): OK. Spongebob Squarepants was rejected because he lacks the required technical skills.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### ➡️ Turn 2: Passing control to `outreach_agent` (Round-Robin)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 🤖 Agent (outreach_agent): OK.  I understand.  I'm ready for the next candidate's information.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### ✅ Group Orchestration Complete"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_group_orchestration(agents, tool_registries, initial_message):\n",
    "    \"\"\"Simulates a round-robin agent group.\"\"\"\n",
    "    print_markdown(f\"### 👤 User: {initial_message}\")\n",
    "    print(\"---\")\n",
    "    \n",
    "    message_for_next_agent = initial_message\n",
    "    history = []\n",
    "\n",
    "    for i, agent in enumerate(agents):\n",
    "        print_markdown(f\"#### ➡️ Turn {i+1}: Passing control to `{agent.name}` (Round-Robin)\")\n",
    "        \n",
    "        full_prompt = f\"{agent.system_prompt}\\n\\n{agent.get_formatted_memory()}\\n\\n**New Task:**\\n{message_for_next_agent}\"\n",
    "        history.append({'role': 'user', 'parts': [{'text': full_prompt}]})\n",
    "        \n",
    "        response = agent.model.generate_content(history, tools=agent.tools)\n",
    "        time.sleep(1)\n",
    "        message = response.candidates[0].content\n",
    "        history.append(message)\n",
    "\n",
    "        if any(part.function_call for part in message.parts):\n",
    "            tool_response_parts = []\n",
    "            for part in message.parts:\n",
    "                if not part.function_call: continue\n",
    "                fc = part.function_call\n",
    "                tool_name = fc.name\n",
    "                tool_args = dict(fc.args)\n",
    "                print(f\"🔧 **Tool Call ({agent.name}):** `{tool_name}` with arguments: `{tool_args}`\\n\" + \"---\")\n",
    "                result = tool_registries[agent.name][tool_name](**tool_args)\n",
    "                tool_response_parts.append({\"function_response\": {\"name\": tool_name, \"response\": {\"content\": result}}})\n",
    "            \n",
    "            history.append({\"role\": \"tool\", \"parts\": tool_response_parts})\n",
    "            response = agent.model.generate_content(history, tools=agent.tools)\n",
    "            time.sleep(1)\n",
    "            message = response.candidates[0].content\n",
    "            history.append(message)\n",
    "\n",
    "        final_text = message.parts[0].text\n",
    "        print_markdown(f\"### 🤖 Agent ({agent.name}): {final_text}\")\n",
    "        \n",
    "        # The output of one agent becomes the input for the next\n",
    "        message_for_next_agent = final_text\n",
    "        \n",
    "    print_markdown(\"#### ✅ Group Orchestration Complete\")\n",
    "\n",
    "# --- Run the Group Simulation ---\n",
    "resume = open(\"spongebob_squarepants.txt\", \"r\").read()\n",
    "# The group is simply a list of the agents in the desired order\n",
    "agent_group = [eval_agent, outreach_agent] \n",
    "\n",
    "run_group_orchestration(\n",
    "    agents=agent_group,\n",
    "    tool_registries=tool_registries,\n",
    "    initial_message=f\"Evaluate this resume: {resume}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
